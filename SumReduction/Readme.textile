h1. Algoritmo  de [+reducción+] paralela para la suma de un vector en cuda.

h2. Resumen

El algoritmo de la reducción para la suma de un vector aclara partes importantes de la programación paralela. Haciendo énfasis en el uso considerado de diferentes técnicas de optimización para la resolución de un mismo algoritmo.

Primero, para resolver el problema en sí, debemos tener en claro la solución de otro problema Sincronización - Global. "La sincronización global en cuda no es posible":http://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0CB0QFjAA&url=http%3A%2F%2Fdeveloper.download.nvidia.com%2Fassets%2Fcuda%2Ffiles%2Freduction.pdf&ei=FDwkVef7H4yiNuHNgLgJ&usg=AFQjCNFLImWbGd0_B5ET1oLqbAL3hZu9Xw&sig2=dsoA8ScPRDg_C3J0A7nFrQ&bvm=bv.89947451,d.b2w ,además de serlo sería  muy costosa a nivel de hardware,lo que la hace también no práctica, dando el hecho de pensar en otras opciones *_-+(que no son tan fáciles como hacer un simple llamado a una barrera de sincronización)+-_*, pero son más versátiles y óptimas.

Por una parte la implementación de técnicas paralelas para la resolución del algoritmo de reducción tendrían que ser orientadas para resolver múltiples problemas que conlleva hacer optimización. Uno de estos problemas son:

* La divergencia entre hilos.
* Conflictos entre bancos de memoria compartida.
* Accesos de memoria.
* Hilos sin ocupación.
* Entre otros.

La implementación aquí realizada ataca el problema desde la divergencia de hilos y la mejora al conflicto entre bancos de memorias,también se añade un nuevo enfoque al trabajo realizado añadiendo varios llamados a kernel.

h2. Implementación:

Se siguió la implementación y sugerencias de "Optimizing Parallel Reduction - Mark Harris":http://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0CB0QFjAA&url=http3A%2F2Fdeveloper.download.nvidia.com%2Fassets%2Fcuda%2Ffiles%2Freduction.pdf&ei=FDwkVef7H4yiNuHNgLgJ&usg=AFQjCNFLImWbGd0_B5ET1oLqbAL3hZu9Xw&sig2=dsoA8ScPRDg_C3J0A7nFrQ&bvm=bv.89947451,d.b2w en la técnica usada Reduction #3: Sequiential Addressing.

<img src="img/s1.png" alt="Solution" />
<img src="img/s2.png" alt="Kernel Levels" />
<img src="img/s3.png" alt="Memory Solution" />



h2. Especificaciones:

Especificación parcial de la máquina en la cuál se corrió el algoritmo.
:::::::::::::::::::::::::::::::::::::::::: CPU ::::::::::::::::::::::::::::::::::::::

* processor       : 1
* vendor_id       : GenuineIntel
* cpu family      : 6
* model           : 58
* model name      : Intel(R) Core(TM) i7-3770K CPU @ 3.50GHz
* stepping        : 9
* cpu MHz         : 1600.000
* cache size      : 8192 KB
* cpu cores       : 4

::::::::::::::::::::::::::::::::::::::::::: GPU ::::::::::::::::::::::::::::::::::::::::::

* Tesla K40c: 3.5
* Global memory:   11519mb
* Shared memory:   48kb
* Constant memory: 64kb
* Block registers: 65536
* Warp size:         32
* Threads per block: 1024
* Max block dimensions: [ 1024, 1024, 64 ]
* Max grid dimensions:  [ 2147483647, 65535, 65535 ]

h3. Gráficas De resultados:

%{color:blue}Tiempos:%

<img src="img/s4.png" alt="Result"/>


¿Por qué la versión paralela (en este caso) no supera las espectativas?, simple : la manera en que se trata de hacer que el programa llegue a la correctitud castiga severamente la convergencia en tiempo.

Al intentar llenar de 0's las locaciones de los valores no utilizados para que la suma no pierda su correctitud tiene un gran impacto en el algoritmo secuencial.


@Daniel Diaz Giraldo@ - UTP
 "@Correo electrónico@(Daniel Diaz)":mailto:daniel@sirius.utp.edu.co
